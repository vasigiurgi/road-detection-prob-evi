{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0efa1a66-0c20-498b-8f7c-be346f5a9355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-05 08:43:49.286763: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-05 08:43:49.287004: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-05 08:43:49.287188: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-05 08:43:49.287409: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-05 08:43:49.287613: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-07-05 08:43:49.287771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5066 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# Camera model architecture\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from libs import ds_layer_p2p_RT\n",
    "from tensorflow.keras.models import model_from_json\n",
    "# ===========================================\n",
    "# Required for memory usage in some RTX 2k,3k series\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "## Memory settings\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25007afb-384c-4dbb-a3b5-7e77f0d2f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_camera_model(img_size, prototypes, singleton_num):\n",
    "    inputs_img = keras.Input(shape=img_size + (3,), name='rgb')\n",
    "    \n",
    "    # Encoder\n",
    "    x = layers.ZeroPadding2D(padding=1, name='Block1_rgb_zp')(inputs_img)\n",
    "    x = layers.Conv2D(32, 4, strides=2, activation='elu', padding='valid', name='Block1_rgb_conv')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='Block2_rgb_zp')(x)\n",
    "    x = layers.Conv2D(32, 3, strides=1, activation='elu', padding='valid', name='Block2_rgb_conv')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='Block3_rgb_zp')(x)\n",
    "    x = layers.Conv2D(64, 4, strides=2, activation='elu', padding='valid', name='Block3_rgb_conv')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='Block4_rgb_zp')(x)\n",
    "    x = layers.Conv2D(64, 3, strides=1, activation='elu', padding='valid', name='Block4_rgb_conv')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='Block5_rgb_zp')(x)\n",
    "    x = layers.Conv2D(128, 4, strides=2, activation='elu', padding='valid', name='Block5_rgb_conv')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='Block51_rgb_zp')(x)\n",
    "    x = layers.Conv2D(128, 3, strides=1, activation='elu', padding='valid', name='Block51_rgb_conv')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='Block52_rgb_zp')(x)\n",
    "    x = layers.Conv2D(256, 4, strides=2, activation='elu', padding='valid', name='Block52_rgb_conv')(x)\n",
    "\n",
    "    # Context module\n",
    "    x = layers.Conv2D(256, 3, padding=\"same\", dilation_rate=(1,1), activation='elu', name='Block6_rgb_conv')(x)\n",
    "    x = layers.Dropout(0.25, name='Block6_rgb_dp')(x)\n",
    "    x = layers.Conv2D(256, 3, padding=\"same\", dilation_rate=(1,1), activation='elu', name='Block7_rgb_conv')(x)\n",
    "    x = layers.Dropout(0.25, name='Block7_rgb_dp')(x)\n",
    "    x = layers.Conv2D(256, 3, padding=\"same\", dilation_rate=(1,2), activation='elu', name='Block8_rgb_conv')(x)\n",
    "    x = layers.Dropout(0.25, name='Block8_rgb_dp')(x)\n",
    "    x = layers.Conv2D(256, 3, padding=\"same\", dilation_rate=(2,4), activation='elu', name='Block9_rgb_conv')(x)\n",
    "    x = layers.Dropout(0.25, name='Block9_rgb_dp')(x)\n",
    "    x = layers.Conv2D(256, 3, padding=\"same\", dilation_rate=(4,8), activation='elu', name='Block10_rgb_conv')(x)\n",
    "    x = layers.Dropout(0.25, name='Block10_rgb_dp')(x)\n",
    "    x = layers.Conv2D(256, 3, padding=\"same\", dilation_rate=(8,16), activation='elu', name='Block11_rgb_conv')(x)\n",
    "    x = layers.Dropout(0.25, name='Block11_rgb_dp')(x)\n",
    "    x = layers.Conv2D(256, 3, padding=\"same\", dilation_rate=(16,32), activation='elu', name='Block12_rgb_conv')(x)\n",
    "    x = layers.Dropout(0.25, name='Block12_rgb_dp')(x)\n",
    "    x = layers.Conv2D(256, 3, padding=\"same\", dilation_rate=(1,1), activation='elu', name='Block13_rgb_conv')(x)\n",
    "    x = layers.Dropout(0.25, name='Block13_rgb_dp')(x)\n",
    "    x = layers.Conv2D(256, 1, padding=\"same\", activation='elu', name='Block14_rgb_conv')(x)\n",
    "    x = layers.Dropout(0.25, name='Block14_rgb_dp')(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = layers.Conv2DTranspose(128, 4, strides=2, activation='elu', padding='same', name='Block15_rgb_convtp')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='Block16_rgb_zp')(x)\n",
    "    x = layers.Conv2D(128, 3, strides=1, activation='elu', padding='valid', name='Block16_rgb_conv')(x)\n",
    "    x = layers.Conv2DTranspose(64, 4, strides=2, activation='elu', padding='same', name='Block162_rgb_convtp')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='Block163_rgb_zp')(x)\n",
    "    x = layers.Conv2D(64, 3, strides=1, activation='elu', padding='valid', name='Block163_rgb_conv')(x)\n",
    "    x = layers.Conv2DTranspose(32, 4, strides=2, activation='elu', padding='same', name='Block17_rgb_convtp')(x)\n",
    "    x = layers.ZeroPadding2D(padding=1, name='Block18_rgb_zp')(x)\n",
    "    x = layers.Conv2D(32, 3, strides=1, activation='elu', padding='valid', name='Block18_rgb_conv')(x)\n",
    "    feature = layers.Conv2DTranspose(8, 4, strides=2, activation='elu', padding='same', name='Block19_rgb_convtp')(x)\n",
    "\n",
    "    # Evidential formulation\n",
    "    x = ds_layer_p2p_RT.DS1(prototypes, name='n_distance_prototype')(feature)\n",
    "    x = ds_layer_p2p_RT.DS1_activate(name='n_prototype_activation')(x)\n",
    "    x = ds_layer_p2p_RT.DS2(singleton_num, name='n_prototype_singleton_mass')(x)\n",
    "    x = ds_layer_p2p_RT.DS2_omega(name='n_prototype_singleton_omega_mass')(x)\n",
    "    x = ds_layer_p2p_RT.DS3_Dempster(name='n_unorm_combined_mass')(x)\n",
    "    x = ds_layer_p2p_RT.DS3_normalize(name='n_norm_combined_mass')(x)\n",
    "    #x = ds_layer_p2p_RT.SelectSingleton(name='n_singleton_mass')(x)\n",
    "    \n",
    "    dBI = ds_layer_p2p_RT.BeliefIntervalDistance(decision_space)(x)\n",
    "\n",
    "    \n",
    "    # Define the camera model\n",
    "    model = keras.Model(inputs=[inputs_img], outputs=dBI)\n",
    "    return model\n",
    "\n",
    "img_size = (384, 1248)  # Camera image size\n",
    "prototypes = 6  # Number of prototypes\n",
    "singleton_num = 2  # Model output channels\n",
    "decision_space = [1,2,3]  # 1: not-road, 2:road 3: ignorance\n",
    "\n",
    "model = get_camera_model(img_size, prototypes, singleton_num)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07b9b543-aeee-48cb-8ae7-d98fa8efdf66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic path from working directory\n",
    "base_path = Path.cwd()\n",
    "\n",
    "# Name of the folder with the model\n",
    "model_name = \"model_camera_rd_evi\"\n",
    "\n",
    "# Saving directory\n",
    "model_path = base_path / model_name\n",
    "model_path.mkdir(parents=True, exist_ok=True)\n",
    "model_json = model.to_json()\n",
    "with open(model_path / f\"{model_name}.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save weights HDF5\n",
    "model.save_weights(model_path / f\"{model_name}_weights.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
