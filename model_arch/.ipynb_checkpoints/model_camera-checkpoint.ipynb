{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0efa1a66-0c20-498b-8f7c-be346f5a9355",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 18:24:05.685697: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-13 18:24:05.688575: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-13 18:24:05.688664: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-13 18:24:05.793051: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-13 18:24:05.794154: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-13 18:24:05.794241: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-13 18:24:05.794298: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 18:24:06.121933: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-13 18:24:06.122033: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-13 18:24:06.122097: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-13 18:24:06.122178: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21749 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# The project has two pipelines: Upsampled Lidar and RGB Camera Images\n",
    "# Camera model architecture\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "\n",
    "# ===========================================\n",
    "# Required for memory usage in some RTX 2k,3k series\n",
    "\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "## Memory settings\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True # to log device placement (on which device the operation ran)\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "set_session(sess)\n",
    "## ---- end Memory setting ----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25007afb-384c-4dbb-a3b5-7e77f0d2f5a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 18:24:11.500865: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-13 18:24:11.500987: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-13 18:24:11.501043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-13 18:24:11.501139: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-13 18:24:11.501196: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-06-13 18:24:11.501247: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 21749 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-13 18:24:12.381838: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: camera_model/assets\n"
     ]
    }
   ],
   "source": [
    "#============================================\n",
    "img_size = (384,1248)\n",
    "rgb_size= (384,1248) # camera RGB images\n",
    "class_num = 2 # model output channels\n",
    "\n",
    "\n",
    "def get_camera_model(img_size, num_classes):\n",
    "    inputs_img = keras.Input(shape=img_size + (3,), name='rgb')\n",
    "    \n",
    "    # Encoder\n",
    "    #B1\n",
    "    x = layers.ZeroPadding2D(padding=1, name='Block1_rgb_zp')(inputs_img)\n",
    "    x = layers.Conv2D(32, 4, strides=2, activation='elu', name='Block1_rgb_conv')(x)\n",
    "    # Add more encoder blocks as needed\n",
    "    #B2: Block 2\n",
    "    x=layers.ZeroPadding2D(padding=1,name='Block2_rgb_zp')(x)\n",
    "    x=layers.Conv2D(32,3,strides=1,activation='elu',name='Block2_rgb_conv')(x) \n",
    "\n",
    "    #B3: Block 3\n",
    "    x=layers.ZeroPadding2D(padding=1,name='Block3_rgb_zp')(x)\n",
    "    x=layers.Conv2D(64,4,strides=2,activation='elu', name='Block3_rgb_conv')(x)  \n",
    "    \n",
    "    #B4: Block 4\n",
    "    x=layers.ZeroPadding2D(padding=1, name='Block4_rgb_zp')(x)\n",
    "    x=layers.Conv2D(64,3,strides=1,activation='elu', name='Block4_rgb_conv')(x) \n",
    "\n",
    "    #B5: Block 5\n",
    "    x=layers.ZeroPadding2D(padding=1,name='Block5_rgb_zp')(x)\n",
    "    x=layers.Conv2D(128,4,strides=2,activation='elu', name='Block5_rgb_conv')(x) \n",
    "    \n",
    "    #B5: Block 51\n",
    "    x=layers.ZeroPadding2D(padding=1, name='Block51_rgb_zp')(x)\n",
    "    x=layers.Conv2D(128,3,strides=1,activation='elu', name='Block52_rgb_conv')(x) \n",
    "\n",
    "    #B5: Block 52\n",
    "    x=layers.ZeroPadding2D(padding=1,name='Block552_rgb_zp')(x)\n",
    "    x=layers.Conv2D(256,4,strides=2,activation='elu', name='Block552_rgb_conv')(x) \n",
    "\n",
    "\n",
    "    # Context module\n",
    "    #B6: Block 6\n",
    "    x=layers.Conv2D(256,3,padding=\"same\",dilation_rate=(1,1),activation='elu', name='Block6_rgb_conv')(x)\n",
    "    x=layers.Dropout(0.25, name='Block6_rgb_dp')(x)\n",
    "\n",
    "    #B7: Block 7\n",
    "    x=layers.Conv2D(256,3,padding=\"same\",dilation_rate=(1,1),activation='elu', name='Block7_rgb_conv')(x)\n",
    "    x=layers.Dropout(0.25, name='Block7_rgb_dp')(x)\n",
    "\n",
    "    #B8: Block 8\n",
    "    x=layers.Conv2D(256,3,padding=\"same\",dilation_rate=(1,2),activation='elu', name='Block8_rgb_conv')(x)\n",
    "    x=layers.Dropout(0.25, name='Block8_rgb_dp')(x)\n",
    "\n",
    "    #B9: Block 9\n",
    "    x=layers.Conv2D(256,3,padding=\"same\",dilation_rate=(2,4),activation='elu', name='Block9_rgb_conv')(x)\n",
    "    x=layers.Dropout(0.25, name='Block9_rgb_dp')(x)\n",
    "\n",
    "    #B10: Block 10\n",
    "    x=layers.Conv2D(256,3,padding=\"same\",dilation_rate=(4,8),activation='elu', name='Block10_rgb_conv')(x)\n",
    "    x=layers.Dropout(0.25, name='Block10_rgb_dp')(x)\n",
    "\n",
    "    #B11: Block 11\n",
    "    x=layers.Conv2D(256,3,padding=\"same\",dilation_rate=(8,16),activation='elu', name='Block11_rgb_conv')(x)\n",
    "    x=layers.Dropout(0.25, name='Block11_rgb_dp')(x)\n",
    "\n",
    "    #B12: Block 12\n",
    "    x=layers.Conv2D(256,3,padding=\"same\",dilation_rate=(16,32),activation='elu', name='Block12_rgb_conv')(x)\n",
    "    x=layers.Dropout(0.25, name='Block12_rgb_dp')(x)\n",
    "\n",
    "    #B13: Block 13\n",
    "    x=layers.Conv2D(256,3,padding=\"same\",dilation_rate=(1,1),activation='elu', name='Block13_rgb_conv')(x)\n",
    "    x=layers.Dropout(0.25, name='Block13_rgb_dp')(x)\n",
    "\n",
    "    #B14: Block 14\n",
    "    x=layers.Conv2D(256,1,padding=\"same\",activation='elu', name='Block14_rgb_conv')(x)\n",
    "    x=layers.Dropout(0.25, name='Block14_rgb_dp')(x)\n",
    "\n",
    "    # Decoder\n",
    "    #B15: Block 15\n",
    "    x=layers.Conv2DTranspose(128,4,strides=2,activation='elu', padding='same', name='Block15_rgb_convtp')(x)\n",
    "\n",
    "    #B16: Block 16\n",
    "    x=layers.ZeroPadding2D(padding=1,name='Block16_rgb_zp')(x)\n",
    "    x=layers.Conv2D(128,3,strides=1,activation='elu', name='Block16_rgb_conv')(x)\n",
    "    \n",
    "    #B17: Block 162\n",
    "    x=layers.Conv2DTranspose(64,4,strides=2,activation='elu', padding='same', name='Block162_rgb_convtp')(x)\n",
    "\n",
    "    #B18: Block 163\n",
    "    x=layers.ZeroPadding2D(padding=1, name='Block163_rgb_zp')(x)\n",
    "    x=layers.Conv2D(64,3,strides=1,activation='elu', name='Block163_rgb_conv')(x)\n",
    "\n",
    "    #B17: Block 17\n",
    "    x=layers.Conv2DTranspose(32,4,strides=2,activation='elu', padding='same', name='Block17_rgb_convtp')(x)\n",
    "\n",
    "    #B18: Block 18\n",
    "    x=layers.ZeroPadding2D(padding=1, name='Block18_rgb_zp')(x)\n",
    "    x=layers.Conv2D(32,3,strides=1,activation='elu', name='Block18_rgb_conv')(x)\n",
    "\n",
    "    #B19: Block 19\n",
    "    x=layers.Conv2DTranspose(8,4,strides=2, activation='elu', padding='same', name='Block19_rgb_convtp')(x)\n",
    "\n",
    "    #B20: Block 20\n",
    "    x=layers.ZeroPadding2D(padding=1, name='Block20_rgb_zp')(x)\n",
    "    x=layers.Conv2D(class_num,3,strides=1, name='Block20_rgb_conv')(x) \n",
    "\n",
    "    # Output layer\n",
    "    output = layers.Conv2D(num_classes, 3, activation='softmax', padding='same', name='rgb_output')(x)\n",
    "\n",
    "    # Define the camera model\n",
    "    camera_model = keras.Model(inputs=inputs_img, outputs=output, name='camera_model')\n",
    "    return camera_model\n",
    "\n",
    "camera_model = get_camera_model(img_size, class_num)\n",
    "# Save the model with custom objects\n",
    "camera_model.save('camera_model', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54fd2e1d-f3cd-463c-ae42-3be90dc01bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
